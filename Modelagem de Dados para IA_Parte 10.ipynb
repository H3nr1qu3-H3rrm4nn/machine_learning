{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Curso de Modelagem de Dados para IA - PARTE 10</center>\n",
    "\n",
    "<img src=\"image.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n",
    "## Aumentando os Dados\n",
    "### Combinando conjuntos de dados\n",
    "Os conjuntos de dados às vezes vêm de fontes diferentes, mas podem ser combinados de maneiras úteis para produzir conjuntos de dados maiores. O Pandas fornece funcionalidade substancial para mesclar, unir e concatenar dataframes de maneira semelhante aos tipos de operações de junção fornecidas pelos bancos de dados. Vamos considerar a questão da concatenação aqui.\n",
    "\n",
    "Conforme mencionado anteriormente, os dados sobre incêndios florestais contêm várias planilhas, incluindo informações sobre incêndios em 2017 que não foram incluídos nos dados históricos agregados na planilha de 2016. Podemos ler esses dados adicionais de 2017 e concatená-los com os dados de 2016 para construir um conjunto de dados completo. Ao fazer isso, no entanto, teremos que fazer um pouco mais de limpeza de dados.\n",
    "\n",
    "Primeiro, vamos ler a planilha de 2017 e comparar os títulos das colunas dos dataframes de 2016 e 2017. Estamos assumindo que as colunas em cada dataframe serão as mesmas, para que possamos concatenar ao longo da dimensão de linha (eixo = 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['YEAR_', 'STATE', 'AGENCY', 'UNIT_ID', 'FIRE_NAME', 'INC_NUM',\n",
      "       'ALARM_DATE', 'CONT_DATE', 'CAUSE', 'COMMENTS', 'REPORT_AC',\n",
      "       'GIS_ACRES', 'C_METHOD', 'OBJECTIVE'],\n",
      "      dtype='object')\n",
      "Index(['YEAR', 'STATE', 'AGENCY', 'UNIT_ID', 'FIRE_NAME', 'INC_NUM',\n",
      "       'ALARM_DATE', 'CONT_DATE', 'CAUSE', 'COMMENTS', 'REPORT_AC',\n",
      "       'GIS_ACRES', 'C_METHOD', 'OBJECTIVE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df16 = pd.read_excel('Fires_100.xlsx', sheet_name='2016')\n",
    "df17 = pd.read_excel('data/wildfires/Fires_100.xlsx', sheet_name='2017', na_values=[''], \n",
    "                   converters= {'ALARM_DATE': pd.to_datetime, 'CONT_DATE': pd.to_datetime})\n",
    "print(df17.columns)\n",
    "print(df16.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os nomes das colunas parecem quase idênticos, mas podemos ver que a primeira coluna em df17 é \"YEAR_\" e a primeira em 2016 é \"YEAR\". Para poder concatenar esses dataframes sem problemas, teremos que renomear a coluna em df17, o que podemos fazer com o método rename no dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df17.rename(columns={'YEAR_': 'YEAR'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo renomeado a coluna (o que fizemos inplace, ou seja, modificando o dataframe diretamente), podemos prosseguir com a concatenação para produzir um novo dataframe com todos os dados, que usaremos para análises posteriores. Observe que, como estamos concatenando para adicionar linhas adicionais ao nosso dataframe inicial, faremos isso ao longo de axis=0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffires = pd.concat((df16, df17), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando dados derivados\n",
    "Às vezes, o conjunto de dados bruto com o qual estamos trabalhando contém as informações básicas de que precisamos para realizar uma análise de interesse, mas não de uma forma que seja imediatamente útil para nós. Nesse caso, podemos querer aumentar o conjunto de dados com novos elementos de dados derivados dos dados brutos. Como os dataframes do pandas são uma estrutura de dados facilmente extensível, é simples adicionar esses novos elementos de dados de forma muito sucinta. Ilustraremos um pouco disso no contexto dos conjuntos de dados de beisebol e incêndios florestais.\n",
    "\n",
    "O conjunto de dados de rebatidas de beisebol contém muitas informações sobre rebatidas, mas estranhamente não contém informações sobre o número de rebatidas simples (ou seja, rebatidas de uma base nas quais o rebatedor atingiu a primeira base com segurança e permaneceu lá até o próximo rebatedor rebater a bola). No beisebol, existem 4 tipos de rebatidas:\n",
    "\n",
    "- simples (uma base, ou 1B)\n",
    "- duplas (duas bases, ou 2B)\n",
    "- triplos (três bases, ou 3B)\n",
    "- home runs (quatro bases, ou HR)\n",
    "\n",
    "Como o conjunto de dados contém informações sobre o número total de acertos **H**, bem como o número de **2B, 3B** e **HR**, podemos definir uma coluna adicional nos dataframes de rebatidas e equipes para calcular o número de singles (**1B**), que é apenas **H-(2B+3B+HR)**. Uma olhada em um dos dataframes mostra que os dados **1B** foram adicionados como a última coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_databank_core_csv(directory):\n",
    "    \"\"\"\n",
    "    read all csv files in the specified baseball databank directory and\n",
    "    populate a dictionary storing each of the tables keyed to its name\n",
    "    \"\"\"\n",
    "    dfs = {}\n",
    "    files = glob.glob('{}/*.csv'.format(directory))\n",
    "    for f in files:\n",
    "        d, name = os.path.split(f)\n",
    "        table = os.path.splitext(name)[0]\n",
    "        df = pd.read_csv(f)\n",
    "        dfs[table] = df\n",
    "    return dfs\n",
    "\n",
    "bbdfs = read_all_databank_core_csv('data/baseballdatabank/core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a few for further processing\n",
    "batting = bbdfs['Batting']\n",
    "pitching = bbdfs['Pitching']\n",
    "teams = bbdfs['Teams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerID</th>\n",
       "      <th>yearID</th>\n",
       "      <th>stint</th>\n",
       "      <th>teamID</th>\n",
       "      <th>lgID</th>\n",
       "      <th>G</th>\n",
       "      <th>AB</th>\n",
       "      <th>R</th>\n",
       "      <th>H</th>\n",
       "      <th>2B</th>\n",
       "      <th>...</th>\n",
       "      <th>SB</th>\n",
       "      <th>CS</th>\n",
       "      <th>BB</th>\n",
       "      <th>SO</th>\n",
       "      <th>IBB</th>\n",
       "      <th>HBP</th>\n",
       "      <th>SH</th>\n",
       "      <th>SF</th>\n",
       "      <th>GIDP</th>\n",
       "      <th>1B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abercda01</td>\n",
       "      <td>1871</td>\n",
       "      <td>1</td>\n",
       "      <td>TRO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>addybo01</td>\n",
       "      <td>1871</td>\n",
       "      <td>1</td>\n",
       "      <td>RC1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>118</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allisar01</td>\n",
       "      <td>1871</td>\n",
       "      <td>1</td>\n",
       "      <td>CL1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>137</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allisdo01</td>\n",
       "      <td>1871</td>\n",
       "      <td>1</td>\n",
       "      <td>WS3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>133</td>\n",
       "      <td>28</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ansonca01</td>\n",
       "      <td>1871</td>\n",
       "      <td>1</td>\n",
       "      <td>RC1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>120</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    playerID  yearID  stint teamID lgID   G   AB   R   H  2B  ...   SB   CS  \\\n",
       "0  abercda01    1871      1    TRO  NaN   1    4   0   0   0  ...  0.0  0.0   \n",
       "1   addybo01    1871      1    RC1  NaN  25  118  30  32   6  ...  8.0  1.0   \n",
       "2  allisar01    1871      1    CL1  NaN  29  137  28  40   4  ...  3.0  1.0   \n",
       "3  allisdo01    1871      1    WS3  NaN  27  133  28  44  10  ...  1.0  1.0   \n",
       "4  ansonca01    1871      1    RC1  NaN  25  120  29  39  11  ...  6.0  2.0   \n",
       "\n",
       "   BB   SO  IBB  HBP  SH  SF  GIDP  1B  \n",
       "0   0  0.0  NaN  NaN NaN NaN   0.0   0  \n",
       "1   4  0.0  NaN  NaN NaN NaN   0.0  26  \n",
       "2   2  5.0  NaN  NaN NaN NaN   1.0  31  \n",
       "3   0  2.0  NaN  NaN NaN NaN   0.0  30  \n",
       "4   2  1.0  NaN  NaN NaN NaN   0.0  25  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batting['1B'] = batting['H'] - batting['2B'] - batting['3B'] - batting['HR']\n",
    "teams['1B'] = teams['H'] - teams['2B'] - teams['3B'] - teams['HR']\n",
    "batting.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício sobre aumento de dados: The Slash Line\n",
    "Agora que você sabe como adicionar colunas de dados adicionais ao seu dataframe, talvez queira obter alguma experiência prática. Em caso afirmativo, você pode adicionar uma célular logo abaixo e trabalhar com o exercício intitulado **The Slash Line**. Este exercício permite calcular estatísticas adicionais de beisebol a partir dos dados brutos no dataframe de rebatidas. A \"Slash Line\" corresponde ao trio de estatísticas de rebatidas conhecidas como Batting Average (BA), On-Base Percentage (OBP) e Slugging Percentage (SLG), fundamentais para a análise de dados de beisebol moderna e podem ser facilmente calculadas com base na dados que temos em mãos. Quando terminar, prossiga para a próxima parte do tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

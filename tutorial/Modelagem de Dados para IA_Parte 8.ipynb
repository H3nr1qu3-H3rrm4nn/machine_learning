{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Curso de Modelagem de Dados para IA - PARTE 8</center>\n",
    "\n",
    "<img src=\"img/image.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n",
    "## Extração e Reorganização dos Dados\n",
    "Às vezes, os dados que se deseja analisar chegam em um formato que não é o ideal para as necessidades ou contêm campos de dados adicionais que podem não ser interessantes. Nesse caso, convém pré-processar os dados para obtê-los em um formato adequado para análise posterior. Ilustramos alguns desses tipos de problemas aqui, no contexto dos dados do Twitter. Conforme observado anteriormente, os arquivos de dados do Twitter estão disponíveis por meio de links de download separados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraindo e reorganizando dados do Twitter\n",
    "O formato padrão para os resultados retornados de uma pesquisa da API do Twitter é um objeto ***JSON (JavaScript Object Notation)*** contendo aproximadamente 40 campos diferentes. Para uma análise focada em retuítes, não são todos esses campos que são de interesse, mas apenas em um subconjunto, conforme descrito abaixo. A estratégia geral será usar os módulos *json* e *csv*, ambos parte da ***Python Standard Library***, para carregar os dados JSON iniciais dos arquivos, extrair campos de interesse e salvar o conjunto de dados reduzido em um arquivo CSV para processamento posterior. O módulo *json* contém o método <span style=\"font-family: 'Courier'\">json.loads</span> que converte um objeto JSON em um dicionário Python. No código a seguir, lemos todos os tweets em um arquivo JSON, extraímos informações de interesse do dicionário resultante e gravamos esse subconjunto de dados de volta em um arquivo CSV, com uma linha por tweet. Um dos desafios de trabalhar com dados textuais como os encontrados em tweets é que eles podem conter caracteres de nova linha (<span style=\"font-family: 'Courier'\">\\n</span>) e retorno de carro (<span style=\"font-family: 'Courier'\">\\r</span>) que podem complicar o processamento de texto; no código abaixo, nós simplesmente substituímos cada um deles por um espaço para que não tenhamos que lidar com eles.\n",
    "\n",
    "Para este exemplo, não será utilizado o conjunto de dados completo, pois é uma violação dos Termos de Serviço do Twitter compartilhar mais de 50.000 tweets em um dia. No entanto, embora o conjunto de dados completo contenha mais de 450.000 tweets, foir reduzido o tamanho total do arquivo de aproximadamente 3,5 Gb para 119 Mb, eliminando a maioria dos cerca de 40 campos que não são de interesse, aderindo assim ao espírito de intenção do Twitter ToS. Para este exemplo, são fornecidos dois arquivos no formato JSON contendo dados de tweet originais coletados com a API de streaming para se ter pelo menos uma noção de como o processo funciona.\n",
    "\n",
    "Os campos escolhidos e que foram mantidos no CSV incluem: <span style=\"font-family: 'Courier'\">id, created_at, lang, user screen_name, user created_at, user id, user followers_count, user friends_count, user time_zone, user utc_offset, retweeted_status, retweeted_status id, retweeted_status user screen_name, retweeted_status uer ID. O código abaixo lê todos os arquivos em uma pasta, extrai dados do subconjunto de campos e salva os resultados em um formato de valores separados por vírgula (CSV) em um arquivo chamado 'climatechange_tweets_sample.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on file:data/twitter/climatechange_2018_11_27_11_30_06_972631.json\n",
      "10000\n",
      "20000\n",
      "Working on file:data/twitter/climatechange_2018_11_26_17_19_15_679824.json\n",
      "30000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "# Open CSV output files for reading and writing\n",
    "input_dir = \"data/twitter/\"\n",
    "output_dir = \"data/twitter/\"\n",
    "hashtag = \"climatechange\"\n",
    "\n",
    "# Open main twitter data CSV file and write header row\n",
    "output_file = output_dir + hashtag + \"_tweets_sample.csv\"\n",
    "f_out = open(output_file, 'w', encoding='utf-8')\n",
    "rowwriter = csv.writer(f_out, delimiter=',', lineterminator='\\n')\n",
    "outputrow = ['tweet_id','tweet_created_at','language','user_screen_name','user_created_at','user_id','followers_count','friends_count','time_zone','utc_offset','retweeted_status','retweet_id','retweet_user_screen_name','retweet_user_id','text']\n",
    "rowwriter.writerow(outputrow)\n",
    "\n",
    "# Define variables\n",
    "inc = 0\n",
    "\n",
    "files = glob.glob(input_dir + '*.json')\n",
    "for file in files:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        print(\"Working on file:\" + file)\n",
    "        for line in f:\n",
    "            tweet = json.loads(line)\n",
    "            if 'user' in tweet:\n",
    "                \n",
    "                # Set standard variables equal to tweet data\n",
    "                tweet_id = tweet['id']\n",
    "                tweet_created_at = tweet['created_at']\n",
    "                text = tweet['text'].replace('\\r', ' ').replace('\\n', ' ')\n",
    "                language = tweet['lang']\n",
    "                user_screen_name = tweet['user']['screen_name']\n",
    "                user_created_at = tweet['user']['created_at']\n",
    "                user_id = tweet['user']['id']\n",
    "                followers_count = tweet['user']['followers_count']\n",
    "                friends_count = tweet['user']['friends_count']\n",
    "                utc_offset = tweet['user']['utc_offset']\n",
    "                time_zone = tweet['user']['time_zone']\n",
    "\n",
    "                # Check if a retweet else original tweet\n",
    "                if 'retweeted_status' in tweet:\n",
    "                    retweeted_status = 1\n",
    "                    retweet_id = tweet['retweeted_status']['id']\n",
    "                    retweet_user_screen_name = tweet['retweeted_status']['user']['screen_name']\n",
    "                    retweet_user_id = tweet['retweeted_status']['user']['id']\n",
    "                else:\n",
    "                    retweeted_status = 0\n",
    "                    retweet_id = \"None\"\n",
    "                    retweet_user_screen_name = \"None\"\n",
    "                    retweet_user_id = \"None\"\n",
    "\n",
    "                # Write to main output file\n",
    "                outputrow = [str(tweet_id), tweet_created_at, language, user_screen_name, user_created_at, str(user_id), str(followers_count), str(friends_count), time_zone, utc_offset, str(retweeted_status), str(retweet_id), retweet_user_screen_name, str(retweet_user_id), text] \n",
    "                rowwriter.writerow(outputrow)\n",
    "\n",
    "                inc += 1\n",
    "                # Optional counter increments variables to track progress, useful for very large files.\n",
    "                if inc%10000 == 0:\n",
    "                    print(inc)\n",
    "\n",
    "# Close the output file\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustando o arquivo CSV para acomodar timestamps de data/hora\n",
    "O arquivo CSV que acabou de ser escrito em disco é um extrato muito menor dos dados de nosso interesse, mas queremos ajustá-lo um pouco para que possamos trabalhar com ele em Pandas com mais facilidade.\n",
    "\n",
    "Dois dos campos no arquivo CSV representam timestamps de data/hora: <span style=\"font-family: 'Courier'\">tweet_created_at</span> e <span style=\"font-family: 'Courier'\">user_created_at</span>. A função <span style=\"font-family: 'Courier'\">pd.read_csv</span> pode receber um argumento adicional indicando que colunas específicas devem ser analisadas como datas (*datetimes*), em vez de strings simples. Infelizmente, os dados do Twitter que extraímos do arquivo JSON estão em um formato que não é o formato padrão de data e hora, por exemplo, Thu Nov 29 19:22:55 +0000 2018. Pandas tem uma função chamada <span style=\"font-family: 'Courier'\">to_datetime</span> que pode não apenas converter strings para objetos datetime, mas pode inferir datetimes de vários formatos diferentes. Essa inferência pode ser bastante lenta para um arquivo grande, no entanto.\n",
    "\n",
    "Felizmente, a função <span style=\"font-family: 'Courier'\">pd.to_datetime</span> pode ser fornecida com uma string de formato específica, para que ela não precise inferir um formato. Ao fornecer uma string de formato explícito para a função de conversão para nossos timestamps de data e hora de tweet, a conversão é bastante rápida (alguns segundos, mesmo para o arquivo de dados completo). As strings de formato são baseadas nos códigos de formato <span style=\"font-family: 'Courier'\">strftime</span> do Python. Se não fornecermos uma dica de formato desse tipo, a conversão levará mais de um minuto para cada chamada de função. No código a seguir, nós:\n",
    "\n",
    "- Fazemos a leitura do arquivo CSV em Pandas\n",
    "- Convertemos dois dos campos que são timestamps de data e hora em objetos de data e hora com uma string de formato específico\n",
    "- Escrevemos um novo arquivo CSV com os dados reformatados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.read_csv(output_dir + 'climatechange_tweets_sample.csv')\n",
    "tweet_df.tweet_created_at = pd.to_datetime(tweet_df.tweet_created_at, format='%a %b %d %H:%M:%S +0000 %Y')\n",
    "tweet_df.user_created_at = pd.to_datetime(tweet_df.user_created_at, format='%a %b %d %H:%M:%S +0000 %Y')\n",
    "tweet_df.to_csv(output_dir + 'climatechange_tweets_fixed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabalhando mais com o arquivo CSV reformatado\n",
    "Tendo ajustado os formatos de data e hora, se quisermos ler nosso novo arquivo CSV em um dataframe pandas, podemos aumentar a chamada <span style=\"font-family: 'Courier'\">pd.read_csv</span> para especificar quais colunas analisar como datas, usando a opção <span style=\"font-family: 'Courier'\">parse_dates</span>. Se não tivéssemos alterado previamente os formatos de data e hora, esta chamada para <span style=\"font-family: 'Courier'\">pd.read_csv</span> seria muito lenta devido à necessidade de fazer inferência de formato de data e hora. Agora que corrigimos os formatos, a análise da data prossegue rapidamente. A função <span style=\"font-family: 'Courier'\">pd.read_csv</span>, no entanto, não permite especificar uma string de formato, por isso precisamos fazer a conversão com a função <span style=\"font-family: 'Courier'\">pd.to_datetime</span> como acima. Veja como é a nova chamada de função <span style=\"font-family: 'Courier'\">read_csv</span>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.read_csv(output_dir + 'climatechange_tweets_fixed.csv', \\\n",
    "                       parse_dates=['tweet_created_at', 'user_created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>language</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>time_zone</th>\n",
       "      <th>utc_offset</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>retweet_user_screen_name</th>\n",
       "      <th>retweet_user_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1067485738931908608</td>\n",
       "      <td>2018-11-27 18:30:07</td>\n",
       "      <td>en</td>\n",
       "      <td>mrbellavia</td>\n",
       "      <td>2008-03-11 03:18:15</td>\n",
       "      <td>14119938</td>\n",
       "      <td>2508</td>\n",
       "      <td>2564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Of course. Why would he say anything else. \"Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1067485742782472192</td>\n",
       "      <td>2018-11-27 18:30:08</td>\n",
       "      <td>en</td>\n",
       "      <td>LesleyRumary</td>\n",
       "      <td>2011-05-29 14:31:50</td>\n",
       "      <td>307372049</td>\n",
       "      <td>167</td>\n",
       "      <td>260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1067440246281900032</td>\n",
       "      <td>Coffeewarblers</td>\n",
       "      <td>311533910</td>\n",
       "      <td>RT @Coffeewarblers: Climate change: CO2 emissi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1067485743466057728</td>\n",
       "      <td>2018-11-27 18:30:08</td>\n",
       "      <td>und</td>\n",
       "      <td>nicolea19082597</td>\n",
       "      <td>2018-09-11 16:55:35</td>\n",
       "      <td>1039558080739135494</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>😬😬 #NaturalPhenomena  #ElNiño #ClimateChange #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1067485753662414855</td>\n",
       "      <td>2018-11-27 18:30:11</td>\n",
       "      <td>en</td>\n",
       "      <td>NLassandrello</td>\n",
       "      <td>2015-07-31 00:44:05</td>\n",
       "      <td>3396454306</td>\n",
       "      <td>108</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1067473981626859523</td>\n",
       "      <td>wildlifeaction</td>\n",
       "      <td>22819917</td>\n",
       "      <td>RT @wildlifeaction: The National Climate Asses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1067485757659643904</td>\n",
       "      <td>2018-11-27 18:30:12</td>\n",
       "      <td>en</td>\n",
       "      <td>thom_lydia</td>\n",
       "      <td>2018-05-08 16:49:47</td>\n",
       "      <td>993895751003623425</td>\n",
       "      <td>165</td>\n",
       "      <td>168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\"UN report says that unless governments act no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44905</th>\n",
       "      <td>1067485674205515777</td>\n",
       "      <td>2018-11-27 18:29:52</td>\n",
       "      <td>en</td>\n",
       "      <td>EvEvangelist</td>\n",
       "      <td>2018-02-19 17:43:56</td>\n",
       "      <td>965643123144654848</td>\n",
       "      <td>19</td>\n",
       "      <td>89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Oh. Dear : 2 ears, 1 mouth . _ for a reason. K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44906</th>\n",
       "      <td>1067485678420852736</td>\n",
       "      <td>2018-11-27 18:29:53</td>\n",
       "      <td>en</td>\n",
       "      <td>MichaelFairfax1</td>\n",
       "      <td>2013-09-07 16:25:59</td>\n",
       "      <td>1755799957</td>\n",
       "      <td>41</td>\n",
       "      <td>401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1067399041519157248</td>\n",
       "      <td>HarryPotterMAGE</td>\n",
       "      <td>828038191974346752</td>\n",
       "      <td>RT @HarryPotterMAGE: There are 3 urgent intern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44907</th>\n",
       "      <td>1067485679507202049</td>\n",
       "      <td>2018-11-27 18:29:53</td>\n",
       "      <td>en</td>\n",
       "      <td>porridgeisgood</td>\n",
       "      <td>2014-09-09 19:38:28</td>\n",
       "      <td>2800466323</td>\n",
       "      <td>3714</td>\n",
       "      <td>2535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1067475114436919296</td>\n",
       "      <td>JWSpry</td>\n",
       "      <td>23023227</td>\n",
       "      <td>RT @JWSpry: HUNDREDS More Frozen Turtles Since...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44908</th>\n",
       "      <td>1067485682925543425</td>\n",
       "      <td>2018-11-27 18:29:54</td>\n",
       "      <td>en</td>\n",
       "      <td>secularjen</td>\n",
       "      <td>2012-02-24 14:18:41</td>\n",
       "      <td>501817486</td>\n",
       "      <td>5645</td>\n",
       "      <td>4582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>#ClimateChange: CO2 emissions rising for first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44909</th>\n",
       "      <td>1067485692517732352</td>\n",
       "      <td>2018-11-27 18:29:56</td>\n",
       "      <td>en</td>\n",
       "      <td>MarcyLauer1</td>\n",
       "      <td>2013-04-02 17:42:42</td>\n",
       "      <td>1322952920</td>\n",
       "      <td>1699</td>\n",
       "      <td>1761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>In just a week, countries will decide how to i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44910 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  tweet_id    tweet_created_at language user_screen_name  \\\n",
       "0      1067485738931908608 2018-11-27 18:30:07       en       mrbellavia   \n",
       "1      1067485742782472192 2018-11-27 18:30:08       en     LesleyRumary   \n",
       "2      1067485743466057728 2018-11-27 18:30:08      und  nicolea19082597   \n",
       "3      1067485753662414855 2018-11-27 18:30:11       en    NLassandrello   \n",
       "4      1067485757659643904 2018-11-27 18:30:12       en       thom_lydia   \n",
       "...                    ...                 ...      ...              ...   \n",
       "44905  1067485674205515777 2018-11-27 18:29:52       en     EvEvangelist   \n",
       "44906  1067485678420852736 2018-11-27 18:29:53       en  MichaelFairfax1   \n",
       "44907  1067485679507202049 2018-11-27 18:29:53       en   porridgeisgood   \n",
       "44908  1067485682925543425 2018-11-27 18:29:54       en       secularjen   \n",
       "44909  1067485692517732352 2018-11-27 18:29:56       en      MarcyLauer1   \n",
       "\n",
       "          user_created_at              user_id  followers_count  \\\n",
       "0     2008-03-11 03:18:15             14119938             2508   \n",
       "1     2011-05-29 14:31:50            307372049              167   \n",
       "2     2018-09-11 16:55:35  1039558080739135494                5   \n",
       "3     2015-07-31 00:44:05           3396454306              108   \n",
       "4     2018-05-08 16:49:47   993895751003623425              165   \n",
       "...                   ...                  ...              ...   \n",
       "44905 2018-02-19 17:43:56   965643123144654848               19   \n",
       "44906 2013-09-07 16:25:59           1755799957               41   \n",
       "44907 2014-09-09 19:38:28           2800466323             3714   \n",
       "44908 2012-02-24 14:18:41            501817486             5645   \n",
       "44909 2013-04-02 17:42:42           1322952920             1699   \n",
       "\n",
       "       friends_count  time_zone  utc_offset  retweeted_status  \\\n",
       "0               2564        NaN         NaN                 0   \n",
       "1                260        NaN         NaN                 1   \n",
       "2                 24        NaN         NaN                 0   \n",
       "3                 52        NaN         NaN                 1   \n",
       "4                168        NaN         NaN                 0   \n",
       "...              ...        ...         ...               ...   \n",
       "44905             89        NaN         NaN                 0   \n",
       "44906            401        NaN         NaN                 1   \n",
       "44907           2535        NaN         NaN                 1   \n",
       "44908           4582        NaN         NaN                 0   \n",
       "44909           1761        NaN         NaN                 0   \n",
       "\n",
       "                retweet_id retweet_user_screen_name     retweet_user_id  \\\n",
       "0                     None                     None                None   \n",
       "1      1067440246281900032           Coffeewarblers           311533910   \n",
       "2                     None                     None                None   \n",
       "3      1067473981626859523           wildlifeaction            22819917   \n",
       "4                     None                     None                None   \n",
       "...                    ...                      ...                 ...   \n",
       "44905                 None                     None                None   \n",
       "44906  1067399041519157248          HarryPotterMAGE  828038191974346752   \n",
       "44907  1067475114436919296                   JWSpry            23023227   \n",
       "44908                 None                     None                None   \n",
       "44909                 None                     None                None   \n",
       "\n",
       "                                                    text  \n",
       "0      Of course. Why would he say anything else. \"Tr...  \n",
       "1      RT @Coffeewarblers: Climate change: CO2 emissi...  \n",
       "2      😬😬 #NaturalPhenomena  #ElNiño #ClimateChange #...  \n",
       "3      RT @wildlifeaction: The National Climate Asses...  \n",
       "4      \"UN report says that unless governments act no...  \n",
       "...                                                  ...  \n",
       "44905  Oh. Dear : 2 ears, 1 mouth . _ for a reason. K...  \n",
       "44906  RT @HarryPotterMAGE: There are 3 urgent intern...  \n",
       "44907  RT @JWSpry: HUNDREDS More Frozen Turtles Since...  \n",
       "44908  #ClimateChange: CO2 emissions rising for first...  \n",
       "44909  In just a week, countries will decide how to i...  \n",
       "\n",
       "[44910 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
